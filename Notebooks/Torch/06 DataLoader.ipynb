{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ba74e0",
   "metadata": {},
   "source": [
    "# Cargadores de datos\n",
    "\n",
    "Los cargadores de datos permiten cargar y administrar los datos de manera sencilla y eficiente. Tanto Tensorflow como Pytorch cuentan con métodos de cargadores de datos. En PyTorch, podemos usar el método <tt>Dataset</tt> para crear una clase que permita administrar los datos.\n",
    "\n",
    "La clase <tt>MyDataset</tt> que presentamos aquí toma una dirección de un archivo .csv y carga los datos de este archivo (usando pandas). Permite entonces administrar los datos, accediendo a cada uno de ellos y separando los datos de sus clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f21b0117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,file_name,idx=0):\n",
    "        #Carga del csv\n",
    "        dataframe = pd.read_csv(file_name, index_col=idx)\n",
    "        #Datos y clases\n",
    "        x = dataframe.iloc[:,:-1].values\n",
    "        y = dataframe.iloc[:,-1].values\n",
    "        self.x = torch.tensor(x, dtype=torch.float)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "        #Tamaño de los datos\n",
    "        self.size = self.x.size()\n",
    "\n",
    "    def __len__(self):\n",
    "        #Regresa tamaño\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        #Regresa un dato\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a501e",
   "metadata": {},
   "source": [
    "Para cargar los datos, sólo llamamos a la clase <tt>MyDataset</tt> y le damos la dirección del archiv .csv que queremos que cargue. Esto genera un objeto que contenga la información de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f53d93ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carga de datos\n",
    "data = MyDataset(file_name='dataset.csv')\n",
    "\n",
    "data.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1b402",
   "metadata": {},
   "source": [
    "Esta clase nos permite visualzar el tamaño de los datos, así como acceder a un dato que le indiquemos para que podamos ver ese dato y su clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d39f584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([569, 30])\n",
      "(tensor([1.3080e+01, 1.5710e+01, 8.5630e+01, 5.2000e+02, 1.0750e-01, 1.2700e-01,\n",
      "        4.5680e-02, 3.1100e-02, 1.9670e-01, 6.8110e-02, 1.8520e-01, 7.4770e-01,\n",
      "        1.3830e+00, 1.4670e+01, 4.0970e-03, 1.8980e-02, 1.6980e-02, 6.4900e-03,\n",
      "        1.6780e-02, 2.4250e-03, 1.4500e+01, 2.0490e+01, 9.6090e+01, 6.3050e+02,\n",
      "        1.3120e-01, 2.7760e-01, 1.8900e-01, 7.2830e-02, 3.1840e-01, 8.1830e-02]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "#Imprime tamaño de datos\n",
    "print(data.size)\n",
    "#Regresa el dato indicado\n",
    "print(data[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3dd6b",
   "metadata": {},
   "source": [
    "## Mini-lotes\n",
    "\n",
    "Los cargadores de datos nos permiten trabajar con mini-lotes (mini-batches) que son de suma importancia en el aprendizaje con redes neuronales, pues permiten un aprendizaje más eficiente. En PyTorch, podemos usar <tt>DataLoader</tt> para administrar los mini-lotes en los datos. De esta forma, podemos administrar el tamaño de los datos e indicar que estos mini-lotes se definan de manera aleatoria en cada época. Necesitamos, pues indicar el tamaño del lote; <tt>shuffle=True</tt> indica que en cada época, los lotes serán aleatorizados.\n",
    "\n",
    "El método <tt>DataLoader</tt> permite manejar la clase <tt>Dataset</tt> por medio de la propiedad <tt>dataset</tt>, la cual nos permite hacer lo mismos procesos de la clase <tt>MyDataset</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ea5f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1.7990e+01, 1.0380e+01, 1.2280e+02, 1.0010e+03, 1.1840e-01, 2.7760e-01,\n",
      "        3.0010e-01, 1.4710e-01, 2.4190e-01, 7.8710e-02, 1.0950e+00, 9.0530e-01,\n",
      "        8.5890e+00, 1.5340e+02, 6.3990e-03, 4.9040e-02, 5.3730e-02, 1.5870e-02,\n",
      "        3.0030e-02, 6.1930e-03, 2.5380e+01, 1.7330e+01, 1.8460e+02, 2.0190e+03,\n",
      "        1.6220e-01, 6.6560e-01, 7.1190e-01, 2.6540e-01, 4.6010e-01, 1.1890e-01]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "#Cargador de datos con mini-lotes\n",
    "loader = DataLoader(data, batch_size=50, shuffle=True)\n",
    "\n",
    "print(loader.dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e77f58",
   "metadata": {},
   "source": [
    "La administración de mini-lotes permite que el modelo de aprendizaje vea sólo $n$ (el tamaño del lote) ejemplos en cada actualización de los parámetros de aprendizaje. Esto mejora el proceso de aprendizaje en redes neuronales, así como su eficiencia, pues procesar mini-lotes tomará menos tiempo que procesar dato por dato. \n",
    "\n",
    "En cada época, se verán todos los lotes, hasta abarcar el total de datos. Podemos ver aquí el tamaó de lotes de los datos que hemos cargado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f6811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de lote x e y: torch.Size([50, 30]), torch.Size([50])\n",
      "Tamaño de lote x e y: torch.Size([50, 30]), torch.Size([50])\n",
      "Tamaño de lote x e y: torch.Size([50, 30]), torch.Size([50])\n",
      "Tamaño de lote x e y: torch.Size([50, 30]), torch.Size([50])\n",
      "Tamaño de lote x e y: torch.Size([50, 30]), torch.Size([50])\n",
      "Tamaño de lote x e y: torch.Size([50, 30]), torch.Size([50])\n",
      "Tamaño de lote x e y: torch.Size([50, 30]), torch.Size([50])\n",
      "Tamaño de lote x e y: torch.Size([50, 30]), torch.Size([50])\n",
      "Tamaño de lote x e y: torch.Size([50, 30]), torch.Size([50])\n",
      "Tamaño de lote x e y: torch.Size([50, 30]), torch.Size([50])\n",
      "Tamaño de lote x e y: torch.Size([50, 30]), torch.Size([50])\n",
      "Tamaño de lote x e y: torch.Size([19, 30]), torch.Size([19])\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in loader:\n",
    "    print('Tamaño de lote x e y: {}, {}'.format(x_batch.size(),y_batch.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9717243",
   "metadata": {},
   "source": [
    "Podemos utilizar la administración de lostes que nos permite el cargador de datos para entrenar más efiecientemente una red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a501bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:12<00:00, 78.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 s, sys: 125 ms, total: 23.2 s\n",
      "Wall time: 12.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Arquitectura de red\n",
    "model = nn.Sequential(nn.Linear(data.size[1], 60), nn.ReLU(), nn.Linear(60, 2), nn.Softmax(1))\n",
    "risk = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "#Entrenamiento con mini-lotes\n",
    "for t in tqdm(range(0, 1000)):\n",
    "    for x_batch, y_batch in loader:\n",
    "        #forwardo\n",
    "        y_pred = model(x_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = risk(y_pred, y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fbc305",
   "metadata": {},
   "source": [
    "Usar un tamaño de lotes de mayor tamaño ahorará tiempo en el procesamiento sin sacrificar la calidad del aprendizaje. Si usamos un lote de tamaño 1, que equivale a procesar ejemplo por ejemplo, el tiempo del entrenamiento será mayor. Si usamos un lote del tamaño del número de datos, que equivale a aprender con todos los datos, el proceso será más rápido, pero muchas veces el aprendizaje será deficiente. Determinar el tamaño óptimo de los lotes es también parte importante del modelo de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6796bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [03:42<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 41s, sys: 168 ms, total: 3min 41s\n",
      "Wall time: 3min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Cargador de datos con mini-lotes\n",
    "loader = DataLoader(data, batch_size=1, shuffle=True)\n",
    "\n",
    "#Arquitectura de red\n",
    "model = nn.Sequential(nn.Linear(data.size[1], 60), nn.Tanh(), nn.Linear(60, 2), nn.Softmax(1))\n",
    "risk = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "#Entrenamiento con mini-lotes\n",
    "for t in tqdm(range(0, 1000)):\n",
    "    for x_batch, y_batch in loader:\n",
    "        y_pred = model(x_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = risk(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0964a55a",
   "metadata": {},
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
